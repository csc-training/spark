{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy (Numerical Python) - Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_list = [[1,2], [4,9], [10,100]]  # list of list\n",
    "# list_of_list + 1\n",
    "# list_of_list * 2\n",
    "\n",
    "# A numpy array is similar to MATLAB matrix\n",
    "numpy_array = array(list_of_list)\n",
    "print(numpy_array)\n",
    "print('Add 1 to each element')\n",
    "print(numpy_array + 1)\n",
    "print('-------')\n",
    "print('Multiply each element by 2')\n",
    "print(numpy_array * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of array is ', numpy_array.shape)\n",
    "print('Rank of array (matrix) is ', numpy_array.ndim)\n",
    "print('Item size is ', numpy_array.dtype)\n",
    "print('Reshaped Array from 3x2 into 2x3:')\n",
    "print(numpy_array.reshape(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = array( [[1,1],\n",
    "               [0,1]] )\n",
    "B = array( [[2,0],\n",
    "                   [3,4]] )\n",
    "\n",
    "print('A')\n",
    "print(A)\n",
    "print('B')\n",
    "print(B)\n",
    "print('\\n')\n",
    "print('A*B')\n",
    "print(A*B)\n",
    "print('\\n')\n",
    "print('A-B')\n",
    "print(A-B)\n",
    "print('\\n')\n",
    "print('A.B')\n",
    "print(A.dot(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more statistical functions\n",
    "print('Sum of matrix A is ', A.sum())\n",
    "print('Sum of matrix B is ', B.sum())\n",
    "print('Min element in marix B is ', B.min())\n",
    "print('Max element in marix B is ', B.max())\n",
    "print('Exponential for B is ', numpy.exp(B))\n",
    "print('Exponential for B is ', numpy.sqrt(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means Clustering with Mlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/K-means_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is one of the most commonly used clustering algorithms that clusters the data points into a predefined number of clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark MLLIB Docs: https://spark.apache.org/docs/latest/mllib-clustering.html#k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('data/unbalance.txt')\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdd_split = rdd.map(lambda line: line.split(' '))\n",
    "rdd_split.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = rdd_split.map(lambda x: (float(x[0]), float(x[1]))).cache()  # Select only the features , convert to float\n",
    "output = rdd_split.map(lambda x: int(x[2])).cache()  # Take the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_python_list = features.collect()\n",
    "# Convert it to a numpy array\n",
    "features_numpy_array = array(features_python_list)\n",
    "# Plot the figure using matplotlib library\n",
    "plt.plot(features_numpy_array[:,0], features_numpy_array[:,1], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model (cluster the data)\n",
    "cluster_model = KMeans.train(features, 8)  # intialization step is crucial in algorithms which are randomized\n",
    "#cluster_model = KMeans.train(features, 8, initializationSteps=100, epsilon=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = array(cluster_model.clusterCenters)\n",
    "\n",
    "plt.scatter(features_numpy_array[:,0], features_numpy_array[:,1]) # Plot the points first\n",
    "\n",
    "for index in range(0,8):  # For every cluster plot the centers\n",
    "    plt.scatter(cluster_centers[index,0], cluster_centers[index,1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output labels using the model generated\n",
    "predicted_labels = array(cluster_model.predict(features).collect())\n",
    "print(predicted_labels)  # have a look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out the unique output labels from array (Using numpy unique function)\n",
    "numpy.unique(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the scatter plot of the points again using the command above but with colors (Hint: use the parameter c to pass color array)\n",
    "plt.scatter(features_numpy_array[:,0], features_numpy_array[:,1], c=predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the computational cost of the cluster\n",
    "cluster_model.computeCost(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
